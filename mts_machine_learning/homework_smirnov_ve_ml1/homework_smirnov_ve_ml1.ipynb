{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ac3175-8ed3-4900-8fc1-93c49bfc16e5",
   "metadata": {},
   "source": [
    "# Соревнование на Kaggle: teta_ml_1_2025  \n",
    "## Предсказание fraud по карточной транзакции  \n",
    "\n",
    "#### Overview  \n",
    "Соревнование в рамках курса от МТС. Задача: детекция фрода карточных транзакций  \n",
    "\n",
    "#### Description  \n",
    "Соревнование по задаче бинарной классификации  \n",
    "\n",
    "#### Evaluation  \n",
    "Оценка метрикой F1 score  \n",
    "\n",
    "### Dataset Description  \n",
    "\n",
    "#### Files  \n",
    "train.csv - the training set  \n",
    "test.csv - the test set  \n",
    "sample_submission.csv - a sample submission file in the correct format  \n",
    "\n",
    "#### Columns  \n",
    "| Column                  | Description |\n",
    "|-------------------------|-------------|\n",
    "| transaction_time        | дата и время совершения транзакции |\n",
    "| merch                  | название или идентификатор продавца или торговой точки, где была совершена транзакция |\n",
    "| cat_id                 | идентификатор категории товара или услуги, к которой относится транзакция |\n",
    "| amount                 | сумма транзакции |\n",
    "| name_1, name_2         | имена, связанные с транзакцией |\n",
    "| gender                 | пол клиента |\n",
    "| street                 | название улицы |\n",
    "| one_city               | город |\n",
    "| us_state               | штат США |\n",
    "| post_code              | почтовый индекс |\n",
    "| lat, lon               | широта и долгота |\n",
    "| population_city        | численность населения города проживания клиента |\n",
    "| jobs                   | уровень занятости |\n",
    "| merchant_lat, merchant_lon | широта и долгота местоположения продавца или точки продажи |\n",
    "| target                 | целевая переменная |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ab567-7b38-44b1-a521-7fc30922f58a",
   "metadata": {},
   "source": [
    "## Intro\n",
    "### Описание финального решения:\n",
    "1) **как обработали данные**;\n",
    "   \n",
    "   - Заполнил пропуски - медианным значением для непрерывных переменных и значениями между значениями слева и справа для дат;\n",
    "   - Категориальные признаки закодировал с помощью CatBoost Encoder (Target Encoding);\n",
    "   - Скалирование непрерывных переменных не показало достаточного прироста в качестве скора - скорее, модель наоборот выдавала более смещенные предикты, чем ожидалось.\n",
    "   - Сгенерировал достаточно много собственных признаков (смотреть ноутбук далее);\n",
    "\n",
    "3) **какой алгоритм вы выбрали**;\n",
    "   \n",
    "   - Использовал затюненное на трешхолд дерево решений из семинарских материалов как BaseLine модель;\n",
    "   - CatBoost для задачи классификации - Final модель.\n",
    "\n",
    "5) **какие особенности использовали при его обучении**;\n",
    "   \n",
    "   - Подбор оптимального трешхолда по обучении модели с целью максимизации оцениваемой в соревновании метрики f1-score;\n",
    "   - Пробовал передавать категориальные признаки как в сам алгоритм, так и кодировать отдельно - кодировка с помощью CatBoost Encoding отдельно показала более хорошие результаты.\n",
    "\n",
    "7) **как проводили валидацию алгоритма**.\n",
    "   \n",
    "   - Работал со стандартным сплитом выборки на test и train (0.25/0.75)\n",
    "   - Использовал Optuna для подбора оптимальных гиперпараметров; тем не менее, решение без подбора оказалось лучше по пересчету метрик на Kaggle.\n",
    "\n",
    "## Outro\n",
    "### Описание вариантов по дальнейшему улучшению итогового подхода:\n",
    "\n",
    "1) **идея №1, которая может улучшить метрику, как ее реализовать (что для этого нужно сделать)**;\n",
    "   \n",
    "   - **Feature Engeneering**\n",
    "   - Больше времени уделить на feature engeneering - как показала практика, именно FE дает крайне значимый прирост в значениях метрики;\n",
    "   - Можно достаточно плотно поработать с координатными признаками;\n",
    "   - Можно много времени уделить на агрерированные показатели по категориям;\n",
    "   - Можно пробовать использовать нелинейные трансформации над признаками.\n",
    "\n",
    "2) **идея №2, которая может улучшить метрику, как ее реализовать (что для этого нужно сделать)**;\n",
    "   \n",
    "   - **Качественный Feature Selection**\n",
    "   - Провести Feature Selection с помощью Permutation Importance и исключить признаки, которые негативно или нейтрально влияют на модель (реализовано по втором соревновании, здесь сугубо выборочно, исходя из ситуации и базового FE);\n",
    "   - Как показывает практика, множество признаков не всего есть хорошо - что и было выявлено во втором соревновании, где огромное число признаков для модели вносило лишь смещение по RMSE-скору.\n",
    "\n",
    "     \n",
    "3) **идея №3, которая может улучшить метрику, как ее реализовать (что для этого нужно сделать)**.\n",
    "   \n",
    "   - **Обеспечить робастность скора по f1-score**\n",
    "   - Лучше проработать подбор трешхолда, а также протестировать модель на более качественной кросс-валидации;\n",
    "   - StratifiedKFold на 5-10 фолдов и оценка скора как усредненное значение - кажется, достаточно релеватный подход;\n",
    "   - Adversarial Validation / Kolmogorov-Smirnov Test - оценка различий в распределениях, так как продакшн-ready модель должна иметь четкий мониторинг по этой части;\n",
    "   - Подумать над Out-of-Time Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976a94d0-2178-4ca1-b736-a0a4856a2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# pip install category-encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6751b7a3-9739-4825-9078-a0c66d374c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fffe79-5cc0-4ee0-a075-1da1d2373b37",
   "metadata": {},
   "source": [
    "## Feature Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43248f61-fb1b-4f20-b591-32573e469060",
   "metadata": {},
   "source": [
    "### Разберемся с transaction_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9e6574-a091-4661-adb2-b79abe9e6d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transaction_time    0.0\n",
       " merch               0.0\n",
       " cat_id              0.0\n",
       " amount              0.0\n",
       " name_1              0.0\n",
       " name_2              0.0\n",
       " gender              0.0\n",
       " street              0.0\n",
       " one_city            0.0\n",
       " us_state            0.0\n",
       " post_code           0.0\n",
       " lat                 0.0\n",
       " lon                 0.0\n",
       " population_city     0.0\n",
       " jobs                0.0\n",
       " merchant_lat        0.0\n",
       " merchant_lon        0.0\n",
       " target              0.0\n",
       " dtype: float64,\n",
       " transaction_time    0.0\n",
       " merch               0.0\n",
       " cat_id              0.0\n",
       " amount              0.0\n",
       " name_1              0.0\n",
       " name_2              0.0\n",
       " gender              0.0\n",
       " street              0.0\n",
       " one_city            0.0\n",
       " us_state            0.0\n",
       " post_code           0.0\n",
       " lat                 0.0\n",
       " lon                 0.0\n",
       " population_city     0.0\n",
       " jobs                0.0\n",
       " merchant_lat        0.0\n",
       " merchant_lon        0.0\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().mean(), test.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd3870c-daa1-4c5b-9d2a-9be1771c7950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019-01-01 00:00', '2019-01-01 00:03', '2019-01-01 00:04', ...,\n",
       "       '2020-03-10 16:07', '2020-03-10 16:07', '2020-03-10 16:08'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(train['transaction_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77688c3-05c7-41e9-854c-c5faa4669770",
   "metadata": {},
   "source": [
    "#### Перевод в число и дату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51ded8a-0686-4daf-89ac-e52f4a6ffb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['transaction_time'] = pd.to_datetime(train['transaction_time'])\n",
    "test['transaction_time'] = pd.to_datetime(test['transaction_time'])\n",
    "\n",
    "train['transaction_date'] = train['transaction_time'].dt.date\n",
    "test['transaction_date'] = test['transaction_time'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912d406-69b5-47b7-a421-6cbe6c5e0ecb",
   "metadata": {},
   "source": [
    "#### Вытащим фичи из дат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1526c63-343f-4dc2-9708-7614974b0675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01 New Year's Day\n",
      "2019-01-21 Martin Luther King Jr. Day\n",
      "2019-02-18 Washington's Birthday\n",
      "2019-05-27 Memorial Day\n",
      "2019-07-04 Independence Day\n",
      "2019-09-02 Labor Day\n",
      "2019-10-14 Columbus Day\n",
      "2019-11-11 Veterans Day\n",
      "2019-11-28 Thanksgiving Day\n",
      "2019-12-25 Christmas Day\n"
     ]
    }
   ],
   "source": [
    "import holidays\n",
    "\n",
    "us_holidays = holidays.US(years=2019)  # Здесь задаю годы, для которых нужны праздники - \n",
    "                                        # ошибся с годом, только позже заметил это, надо не только за 2019 брать\n",
    "\n",
    "for date, name in sorted(us_holidays.items()):\n",
    "    print(date, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d479bb3-acb9-4e43-a465-ab587c44e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём список праздников для США в 2019 году - СНОВА ОШИБКА\n",
    "us_holidays = holidays.US(years=[2019])\n",
    "\n",
    "# Функция для получения названия праздника\n",
    "def get_holiday_name(date):\n",
    "    return us_holidays.get(date) if date in us_holidays else \"No Holiday\"\n",
    "\n",
    "# Функция для биннинга времени суток\n",
    "def assign_time_of_day(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return \"morning\" \n",
    "    elif 12 <= hour < 18:\n",
    "        return \"afternoon\"\n",
    "    elif 18 <= hour < 24:\n",
    "        return \"evening\" \n",
    "    else:\n",
    "        return \"night\"\n",
    "\n",
    "# Обработка train\n",
    "train['transaction_time_month'] = train['transaction_time'].dt.month\n",
    "train['transaction_time_week'] = train['transaction_time'].dt.isocalendar().week\n",
    "train['transaction_time_day_of_the_week'] = train['transaction_time'].dt.dayofweek\n",
    "train['transaction_time_hour'] = train['transaction_time'].dt.hour\n",
    "train['transaction_time_minute'] = train['transaction_time'].dt.minute\n",
    "\n",
    "train[\"transaction_time_holidays\"] = train[\"transaction_time\"].apply(get_holiday_name)\n",
    "train['transaction_time_binning_by_part'] = train['transaction_time_hour'].apply(assign_time_of_day)\n",
    "\n",
    "# Обработка test\n",
    "test['transaction_time_month'] = test['transaction_time'].dt.month\n",
    "test['transaction_time_week'] = test['transaction_time'].dt.isocalendar().week\n",
    "test['transaction_time_day_of_the_week'] = test['transaction_time'].dt.dayofweek\n",
    "test['transaction_time_hour'] = test['transaction_time'].dt.hour\n",
    "test['transaction_time_minute'] = test['transaction_time'].dt.minute\n",
    "\n",
    "test[\"transaction_time_holidays\"] = test[\"transaction_time\"].apply(get_holiday_name)\n",
    "test['transaction_time_binning_by_part'] = test['transaction_time_hour'].apply(assign_time_of_day)\n",
    "\n",
    "# NICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d234fd-0d25-441a-9673-6561568b7a3a",
   "metadata": {},
   "source": [
    "## Снова работаем с расстояниями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac40cb5f-ca68-4ba1-abb5-a22529058cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import atan2, cos, radians, sin, sqrt\n",
    "\n",
    "\n",
    "def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float, n_digits: int = 0) -> float:\n",
    "    \"\"\"\n",
    "        Функция для расчёта расстояния от точки А до Б по прямой\n",
    "\n",
    "        :param lat1: Широта точки А\n",
    "        :param lon1: Долгота точки А\n",
    "        :param lat2: Широта точки Б\n",
    "        :param lon2: Долгота точки Б\n",
    "        :param n_digits: Округляем полученный ответ до n знака после запятой\n",
    "        :return: Дистанция по прямой с точностью до n_digits\n",
    "    \"\"\"\n",
    "\n",
    "    lat1, lon1, lat2, lon2 = round(lat1, 6), round(lon1, 6), round(lat2, 6), round(lon2, 6)\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi / 2) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2) ** 2\n",
    "\n",
    "    return round(2 * 6372800 * np.arctan2(np.sqrt(a), np.sqrt(1 - a)), n_digits)  # метры.сантиметры\n",
    "\n",
    "\n",
    "def bearing_degree(lat1: float, lon1: float, lat2: float, lon2: float, n_digits: int = 0) -> float:\n",
    "    \"\"\"\n",
    "        Функция для расчёта угла между прямой [((lat1, lon1), (lat2, lon2)), (нулевой мередиан)]\n",
    "\n",
    "        :param lat1: Широта точки А\n",
    "        :param lon1: Долгота точки А\n",
    "        :param lat2: Широта точки Б\n",
    "        :param lon2: Долгота точки Б\n",
    "        :param n_digits: Округляем полученный ответ до n знака после запятой\n",
    "        :return: Значение угла с точностью до n_digits\n",
    "    \"\"\"\n",
    "\n",
    "    lat1, lon1 = np.radians(round(lat1, 6)), np.radians(round(lon1, 6))\n",
    "    lat2, lon2 = np.radians(round(lat2, 6)), np.radians(round(lon2, 6))\n",
    "\n",
    "    dlon = (lon2 - lon1)\n",
    "    numerator = np.sin(dlon) * np.cos(lat2)\n",
    "    denominator = np.cos(lat1) * np.sin(lat2) - (np.sin(lat1) * np.cos(lat2) * np.cos(dlon))\n",
    "\n",
    "    theta = np.arctan2(numerator, denominator)\n",
    "    theta_deg = (np.degrees(theta) + 360) % 360\n",
    "\n",
    "    return round(theta_deg, n_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3add72b9-4334-4527-a99a-e919f662efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bearing_degree_1'] = bearing_degree(train['lat'], train['lon'], train['merchant_lat'], train['merchant_lon'], ).values\n",
    "test['bearing_degree_1'] = bearing_degree(test['lat'], test['lon'], test['merchant_lat'], test['merchant_lon'], ).values\n",
    "train['bearing_degree_2'] = bearing_degree(train['lat'], train['lon'], 0, 0, ).values\n",
    "test['bearing_degree_2'] = bearing_degree(test['lat'], test['lon'], 0, 0, ).values\n",
    "\n",
    "train['bearing_degree_3'] = bearing_degree(0, 0, train['merchant_lat'], train['merchant_lon'], ).values\n",
    "test['bearing_degree_3'] = bearing_degree(0, 0, test['merchant_lat'], test['merchant_lon'], ).values\n",
    "\n",
    "train['hav_dist_1'] = haversine_distance(train['lat'], train['lon'], train['merchant_lat'], train['merchant_lon'], ).values\n",
    "test['hav_dist_1'] = haversine_distance(test['lat'], test['lon'], test['merchant_lat'], test['merchant_lon'], ).values\n",
    "\n",
    "\n",
    "train['hav_dist_2'] = haversine_distance(train['lat'], train['lon'], 0, 0, ).values\n",
    "test['hav_dist_2'] = haversine_distance(test['lat'], test['lon'], 0, 0, ).values\n",
    "\n",
    "train['hav_dist_3'] = haversine_distance(0, 0, train['merchant_lat'], train['merchant_lon'], ).values\n",
    "test['hav_dist_3'] = haversine_distance(0, 0, test['merchant_lat'], test['merchant_lon'], ).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcce2fd-bea0-4628-a81a-4e2b6f178a9c",
   "metadata": {},
   "source": [
    "### Логарифмизация и ночные транзакции, превышение порога (перцентиль уровня 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5712ae4c-0b82-456f-b559-94f5f039a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Логарифм суммы\n",
    "train['amount_log'] = np.log1p(train['amount']) \n",
    "test['amount_log'] = np.log1p(test['amount'])\n",
    "\n",
    "\n",
    "# Фильтруем ночные транзакции\n",
    "train_night = train[train['transaction_time_binning_by_part'] == \"night\"]\n",
    "test_night = test[test['transaction_time_binning_by_part'] == \"night\"]\n",
    "\n",
    "# Агрегаты по ночным транзакциям для каждого дня\n",
    "train_night_agg = train_night.groupby('transaction_date')['amount'].agg(\n",
    "    sum_by_night_part='sum',\n",
    "    mean_by_night_part='mean',\n",
    "    median_by_night_part='median'\n",
    ").reset_index()\n",
    "\n",
    "test_night_agg = test_night.groupby('transaction_date')['amount'].agg(\n",
    "    sum_by_night_part='sum',\n",
    "    mean_by_night_part='mean',\n",
    "    median_by_night_part='median'\n",
    ").reset_index()\n",
    "\n",
    "# Объединяем\n",
    "train = train.merge(train_night_agg, on='transaction_date', how='left')\n",
    "test = test.merge(test_night_agg, on='transaction_date', how='left')\n",
    "\n",
    "# 90-й перцентиль для каждого дня\n",
    "train_90 = train.groupby('transaction_date')['amount'].quantile(0.9).reset_index(name='percentile_90')\n",
    "test_90 = test.groupby('transaction_date')['amount'].quantile(0.9).reset_index(name='percentile_90')\n",
    "\n",
    "# Объединяем 90-й перцентиль с основными данными\n",
    "train = train.merge(train_90, on='transaction_date', how='left')\n",
    "test = test.merge(test_90, on='transaction_date', how='left')\n",
    "\n",
    "# Сумма транзакций выше 90-го перцентиля по дням\n",
    "train_high = train[train['amount'] > train['percentile_90']].groupby('transaction_date')['amount'].sum().reset_index(name='sum_more_than_90')\n",
    "test_high = test[test['amount'] > test['percentile_90']].groupby('transaction_date')['amount'].sum().reset_index(name='sum_more_than_90')\n",
    "\n",
    "# Объединяем с основными данными\n",
    "train = train.merge(train_high, on='transaction_date', how='left')\n",
    "test = test.merge(test_high, on='transaction_date', how='left')\n",
    "\n",
    "# Заполняем пропущенные значения нулями (если в день не было ночных транзакций?)\n",
    "train[['sum_by_night_part', 'mean_by_night_part', 'median_by_night_part', 'sum_more_than_90']] = \\\n",
    "    train[['sum_by_night_part', 'mean_by_night_part', 'median_by_night_part', 'sum_more_than_90']].fillna(0)\n",
    "\n",
    "test[['sum_by_night_part', 'mean_by_night_part', 'median_by_night_part', 'sum_more_than_90']] = \\\n",
    "    test[['sum_by_night_part', 'mean_by_night_part', 'median_by_night_part', 'sum_more_than_90']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0983f76-8843-4d24-9c1d-a3ab032ec0d8",
   "metadata": {},
   "source": [
    "### Статистики по полу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf70223-6477-41a3-bc1a-e6506788745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аггрегируем данные по дню и полу для train по транзакциям\n",
    "gender_daily_stats_train = train.groupby(['transaction_date', 'gender']).agg(\n",
    "    count=('amount', 'size'),           # Количество\n",
    "    mean_amount=('amount', 'mean'),     # Среднее  \n",
    "    median_amount=('amount', 'median'), # Медианное  \n",
    "    total_sum=('amount', 'sum')        # Сумма \n",
    ").reset_index()\n",
    "\n",
    "# Объединяем результаты с исходным train\n",
    "train = pd.merge(train, gender_daily_stats_train, on=['transaction_date', 'gender'], how='left')\n",
    "\n",
    "# Аггрегируем данные по дню и полу для test\n",
    "gender_daily_stats_test = test.groupby(['transaction_date', 'gender']).agg(\n",
    "    count=('amount', 'size'),           # Количество \n",
    "    mean_amount=('amount', 'mean'),     # Среднее  \n",
    "    median_amount=('amount', 'median'), # Медианное  \n",
    "    total_sum=('amount', 'sum')        # Сумма \n",
    ").reset_index()\n",
    "\n",
    "# Объединяем результаты с исходным test\n",
    "test = pd.merge(test, gender_daily_stats_test, on=['transaction_date', 'gender'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783adb90-e034-4f7d-b797-3f71cf103ed8",
   "metadata": {},
   "source": [
    "### Подумать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51171fcd-787f-4aa9-abb3-24110e9aabd7",
   "metadata": {},
   "source": [
    "#### Бинаризация (дискретизация) числовых признаков\n",
    "\n",
    "Наконец, подумаем о предсказании стоимости квартиры по расстоянию до ближайшей станции метро $x_j$.\n",
    "\n",
    "Может оказаться, что самые дорогие квартиры расположены где-то в 5-10 минутах ходьбы от метро, а те, что ближе или дальше, стоят не так дорого. В этом случае зависимость целевой переменной от признака не будет линейной. Чтобы сделать линейную модель подходящей, мы можем бинаризовать признак. Для этого выберем некоторую сетку точек ${t_1, \\dots, t_m}$. Это может быть равномерная сетка между минимальным и максимальным значением признака или, например, сетка из эмпирических квантилей. Добавим сюда точки $t_0 = -\\infty$ и $t_{m+1} = +\\infty$.  \n",
    "\n",
    "Новые признаки зададим как:\n",
    "$$\\large\n",
    "b_i(x) = [t_{i-1} < x_j \\leq t_i], \\quad i = 1, \\dots, m+1.\n",
    "$$\n",
    "Линейная модель над этими признаками будет выглядеть как:\n",
    "$$\\large\n",
    "a(x) = w_1 [t_0 < x_j \\leq t_1] + \\dots + w_{m+1} [t_m < x_j \\leq t_{m+1}] + \\dots,\n",
    "$$\n",
    "то есть мы найдём свой прогноз стоимости квартиры для каждого интервала расстояния до метро. Такой подход позволит учесть нелинейную зависимость между признаком и целевой переменной.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3957d7-1894-4745-acbe-86b688555796",
   "metadata": {},
   "source": [
    "### Подумать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e556ab20-b857-45b1-b693-37f250e85abd",
   "metadata": {},
   "source": [
    "#### DBSKAN / Optics\n",
    "#### Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27f0ac-e104-4c89-a7ac-e57ab1d42258",
   "metadata": {},
   "source": [
    "### CatBoost Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e414382b-17a5-47df-b1db-d5988c3c0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ts_transaction_time'] = pd.to_datetime(train['transaction_time']).values.astype('int64') // 10**9\n",
    "test['ts_transaction_time'] = pd.to_datetime(test['transaction_time']).values.astype('int64') // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8907099d-bb4b-4bfa-b04f-98990371f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем все столбцы в строки перед кодированием\n",
    "cat_columns = ['gender', 'jobs', 'transaction_time_holidays', 'transaction_time_binning_by_part']\n",
    "for col in cat_columns:\n",
    "    train[col] = train[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "train[cat_columns] = train[cat_columns].fillna('пропуск')\n",
    "test[cat_columns] = test[cat_columns].fillna('пропуск')\n",
    "\n",
    "\n",
    "numeric_features = [\n",
    "    'amount',\n",
    "    'lat',\n",
    "    'lon',\n",
    "    'population_city',\n",
    "    'merchant_lat',\n",
    "    'merchant_lon',\n",
    "    'amount_log',\n",
    "    'sum_by_night_part',\n",
    "    'mean_by_night_part',\n",
    "    'median_by_night_part',\n",
    "    'percentile_90',\n",
    "    'sum_more_than_90',\n",
    "    'count',\n",
    "    'mean_amount',\n",
    "    'median_amount',\n",
    "    'total_sum',\n",
    "    'transaction_time_month',\n",
    "    'transaction_time_week',\n",
    "    'transaction_time_day_of_the_week',\n",
    "    'transaction_time_hour',\n",
    "    'transaction_time_minute',\n",
    "    'bearing_degree_1',\n",
    "    'bearing_degree_2',\n",
    "    'bearing_degree_3',\n",
    "    'hav_dist_1',\n",
    "    'hav_dist_2',\n",
    "    'hav_dist_3'\n",
    "]\n",
    "\n",
    "cat_columns = [\n",
    "    'merch',\n",
    "    'cat_id',\n",
    "    'name_1',\n",
    "    'name_2',\n",
    "    'gender',  \n",
    "    'street',\n",
    "    'one_city',\n",
    "    'us_state',\n",
    "    'jobs',  \n",
    "    'post_code',\n",
    "    'transaction_time_holidays',  \n",
    "    'transaction_time_binning_by_part' \n",
    "]\n",
    "\n",
    "target_enc = ce.CatBoostEncoder(cols=cat_columns)\n",
    "target_enc = target_enc.fit(train[cat_columns], train['target'])\n",
    "train = train.join(target_enc.transform(train[cat_columns]).add_suffix('_cb'))\n",
    "test = test.join(target_enc.transform(test[cat_columns]).add_suffix('_cb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2b2f284-0d79-47d5-a78f-fe1519f93b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transaction_time', 'merch', 'cat_id', 'amount', 'name_1', 'name_2',\n",
       "       'gender', 'street', 'one_city', 'us_state', 'post_code', 'lat', 'lon',\n",
       "       'population_city', 'jobs', 'merchant_lat', 'merchant_lon', 'target',\n",
       "       'transaction_date', 'transaction_time_month', 'transaction_time_week',\n",
       "       'transaction_time_day_of_the_week', 'transaction_time_hour',\n",
       "       'transaction_time_minute', 'transaction_time_holidays',\n",
       "       'transaction_time_binning_by_part', 'bearing_degree_1',\n",
       "       'bearing_degree_2', 'bearing_degree_3', 'hav_dist_1', 'hav_dist_2',\n",
       "       'hav_dist_3', 'amount_log', 'sum_by_night_part', 'mean_by_night_part',\n",
       "       'median_by_night_part', 'percentile_90', 'sum_more_than_90', 'count',\n",
       "       'mean_amount', 'median_amount', 'total_sum', 'ts_transaction_time',\n",
       "       'merch_cb', 'cat_id_cb', 'name_1_cb', 'name_2_cb', 'gender_cb',\n",
       "       'street_cb', 'one_city_cb', 'us_state_cb', 'jobs_cb', 'post_code_cb',\n",
       "       'transaction_time_holidays_cb', 'transaction_time_binning_by_part_cb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa54a6c9-1be5-4812-943a-de199a4f129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = [\n",
    "    'amount', \n",
    "    'amount_log', \n",
    "    'population_city', \n",
    "    'lat', \n",
    "    'lon', \n",
    "    'merchant_lat', \n",
    "    'merchant_lon', \n",
    "    'bearing_degree_1',\n",
    "    'bearing_degree_2', \n",
    "    'bearing_degree_3', \n",
    "    'hav_dist_1', \n",
    "    'hav_dist_2',\n",
    "    'hav_dist_3',\n",
    "    'transaction_time_month', \n",
    "    'transaction_time_week',\n",
    "    'transaction_time_day_of_the_week', \n",
    "    'transaction_time_hour',\n",
    "    'transaction_time_minute', \n",
    "    'sum_by_night_part', \n",
    "    'mean_by_night_part', \n",
    "    'median_by_night_part',\n",
    "    'percentile_90', \n",
    "    'sum_more_than_90', \n",
    "    'count', \n",
    "    'mean_amount',\n",
    "    'median_amount', \n",
    "    'total_sum',\n",
    "    'merch_cb', \n",
    "    'cat_id_cb', \n",
    "    'name_1_cb', \n",
    "    'name_2_cb',\n",
    "    'gender_cb', \n",
    "    'street_cb', \n",
    "    'one_city_cb',\n",
    "    'us_state_cb', \n",
    "    'jobs_cb',\n",
    "    'post_code_cb',\n",
    "    'transaction_time_holidays_cb',\n",
    "    'transaction_time_binning_by_part_cb'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa4418-3d1a-4ede-a36f-cf4ad19cf8e8",
   "metadata": {},
   "source": [
    "## Baseline Model из лекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a7f5509-d997-4a48-8b81-fdc1ae9cb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# автоподбор трешхолда из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daddc33d-4a6e-4895-9b61-69d029fe9ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3378, number of negative: 586445\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7111\n",
      "[LightGBM] [Info] Number of data points in the train set: 589823, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005727 -> initscore=-5.156795\n",
      "[LightGBM] [Info] Start training from score -5.156795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5428809325562032"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = DecisionTreeClassifier(max_depth=5, random_state=15, )\n",
    "model = LGBMClassifier(n_estimators=50, random_state=14, )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train[model_features], train['target'], test_size=0.25, random_state=42,\n",
    "    stratify=train['target']\n",
    ")\n",
    "\n",
    "\n",
    "%time\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict_proba(X_test)\n",
    "\n",
    "predictions = predictions[:, 1]\n",
    "\n",
    "# TODO: подобрать threshold модели (поменять np.mean(predictions))\n",
    "predictions_binary = predictions >= np.mean(predictions)\n",
    "\n",
    "f1_score(y_test, predictions_binary)\n",
    "\n",
    "\n",
    "# ВНИМАНИЕ: f1 = 0.3692127368626685 без фича инжиниринга\n",
    "\n",
    "# ДВОЙНОЕ ВНИМАНИЕ: f1 = 0.5428809325562032 с фича инжинирингом. даже без трешхолда"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c968e3-b21d-4bdf-ad31-52a3906e4a1f",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc3e26ea-432a-4061-9f4e-2175439ed18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальный порог: 0.46\n",
      "F1-score: 0.8356940509915014\n"
     ]
    }
   ],
   "source": [
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train[model_features], train['target'], test_size=0.25, random_state=42,\n",
    "    stratify=train['target']\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model_catboost = CatBoostClassifier(iterations=50, random_state=14, verbose=0)\n",
    "model_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Получение вероятностей на валидации\n",
    "predictions_proba_val = model_catboost.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Функция для поиска оптимального порога\n",
    "def find_best_threshold(y_true, predictions):\n",
    "    best_threshold, best_f1 = 0, 0\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        f1 = f1_score(y_true, predictions >= threshold)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_threshold = f1, threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Оптимальный порог по валидационной выборке\n",
    "best_threshold, best_f1 = find_best_threshold(y_val, predictions_proba_val)\n",
    "print(f\"Оптимальный порог: {best_threshold}\")\n",
    "print(f\"F1-score: {best_f1}\")\n",
    "\n",
    "# Оптимальный порог: 0.46\n",
    "# F1-score: 0.8356940509915014\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297c75f-4fc3-4670-acf8-8fcc58d40e13",
   "metadata": {},
   "source": [
    "### CatBoost с затюненными гиперпараметрами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf2bee-6a97-4ce4-8420-8514c296bad8",
   "metadata": {},
   "source": [
    "Ниже код для Optuna (в конце ноутбука)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcf65874-4e7f-48c6-a5ba-272930ddbfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальный порог: 0.29\n",
      "Лучший F1-score: 0.8554437328453797\n",
      "F1-score на валидации с оптимальным порогом: 0.8554437328453797\n"
     ]
    }
   ],
   "source": [
    "# Оптимальные параметры\n",
    "best_params = {\n",
    "    'iterations': 200,\n",
    "    'learning_rate': 0.24008436863847432,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 5.064713404918217,\n",
    "    'border_count': 128\n",
    "}\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train[model_features], train['target'], test_size=0.25, random_state=42,\n",
    "    stratify=train['target']\n",
    ")\n",
    "\n",
    "# Обучение модели с оптимальными параметрами - сразу передаю их\n",
    "model_catboost = CatBoostClassifier(\n",
    "    iterations=best_params['iterations'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    depth=best_params['depth'],\n",
    "    l2_leaf_reg=best_params['l2_leaf_reg'],\n",
    "    border_count=best_params['border_count'],\n",
    "    random_state=14,\n",
    "    verbose=0\n",
    ")\n",
    "model_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Получение вероятностей на валидации\n",
    "predictions_proba_val = model_catboost.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Функция для поиска оптимального порога - сделал по-простому\n",
    "def find_best_threshold(y_true, predictions):\n",
    "    best_threshold, best_f1 = 0, 0\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        f1 = f1_score(y_true, predictions >= threshold)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_threshold = f1, threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Оптимальный порог по валидационной выборке\n",
    "best_threshold, best_f1 = find_best_threshold(y_val, predictions_proba_val)\n",
    "print(f\"Оптимальный порог: {best_threshold}\")\n",
    "print(f\"Лучший F1-score: {best_f1}\")\n",
    "\n",
    "# Применяем оптимальный порог\n",
    "predictions_val = predictions_proba_val >= best_threshold\n",
    "\n",
    "# Получаем F1-score на валидационной выборке (оптимальный порог)\n",
    "f1_val = f1_score(y_val, predictions_val)\n",
    "print(f\"F1-score на валидации с оптимальным порогом: {f1_val}\")\n",
    "\n",
    "\n",
    "# Оптимальный порог: 0.29\n",
    "# Лучший F1-score: 0.8554437328453797\n",
    "# F1-score на валидации с оптимальным порогом: 0.8554437328453797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "967eaa7a-7280-4501-bd7b-258fbae4fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания для тестовых данных\n",
    "test_preds = model_catboost.predict_proba(test[model_features])[:, 1]\n",
    "test_predictions = test_preds >= best_threshold\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'index': test.index,\n",
    "    'prediction': test_predictions\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e29fbed8-b31c-4766-81ca-37f777f051ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания для тестового датасета\n",
    "predictions_proba_test = model_catboost.predict_proba(test[model_features])[:, 1]\n",
    "predictions_binary_test = (predictions_proba_test >= best_threshold).astype(int)\n",
    "\n",
    "results_test = pd.DataFrame({\n",
    "    'index': test.index,  \n",
    "    'prediction': predictions_binary_test\n",
    "})\n",
    "\n",
    "results_test.to_excel('submission.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3dc9a-18ef-40b4-a35b-0506b953bb91",
   "metadata": {},
   "source": [
    "#### Гиперпараметры\n",
    "\n",
    "**Hyperopt**\n",
    "\n",
    "В библиотеке [Hyperopt](http://hyperopt.github.io/hyperopt/) реализованы три метода оптимизации гиперпараметров:\n",
    "\n",
    "- Random Search\n",
    "- TPE\n",
    "- [Adaptive TPE](https://github.com/electricbrainio/hypermax)\n",
    "\n",
    "У них есть небольшой [туториал](https://github.com/hyperopt/hyperopt/wiki/FMin) по тому, как начать пользоваться библиотекой. Кроме того, у них есть обёртка над sklearn, позволяющая работать с моделями оттуда: [Hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn).\n",
    "\n",
    "**Optuna**\n",
    "\n",
    "В библиотеке [Optuna](https://optuna.org/) реализованы те же методы оптимизации, что и в Hyperopt, но по многим параметрам она оказывается удобнее. Хорошее сравнение Optuna и Hyperopt можно найти [здесь](https://neptune.ai/blog/optuna-vs-hyperopt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03b4e45d-0936-4793-9fb1-b24c70de1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лучшие параметры:\n",
    "# {'iterations': 200, 'learning_rate': 0.24008436863847432, 'depth': 10, 'l2_leaf_reg': 5.064713404918217, 'border_count': 128}\n",
    "# Лучший F1-score: 0.8554437328453797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ba49e57-bbd5-47da-b2c1-d44fe23e52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train[model_features], train['target'], test_size=0.25, random_state=42,\n",
    "    stratify=train['target']\n",
    ")\n",
    "\n",
    "# Функция для поиска оптимального порога\n",
    "def find_best_threshold(y_true, predictions):\n",
    "    best_threshold, best_f1 = 0, 0\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        f1 = f1_score(y_true, predictions >= threshold)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_threshold = f1, threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Определяем целевую функцию для Optuna\n",
    "def objective(trial):\n",
    "    # Определяем параметры\n",
    "    iterations = trial.suggest_int('iterations', 50, 200, step=50)  # Количество итераций\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)  # Скорость обучения\n",
    "    depth = trial.suggest_int('depth', 3, 10)  # Глубина дерева\n",
    "    l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 1, 10)  # Регуляризация\n",
    "    border_count = trial.suggest_int('border_count', 32, 255, step=32)  # Количество границ\n",
    "\n",
    "    # Создаем модель с гиперпараметрами по Optuna\n",
    "    model_catboost = CatBoostClassifier(\n",
    "        iterations=iterations,\n",
    "        learning_rate=learning_rate,\n",
    "        depth=depth,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        border_count=border_count,\n",
    "        random_state=14,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Обучаем\n",
    "    model_catboost.fit(X_train, y_train)\n",
    "    \n",
    "    # Получаем предсказания на валидации\n",
    "    predictions_proba_val = model_catboost.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Оптимальный порог по валидационной выборке\n",
    "    best_threshold, best_f1 = find_best_threshold(y_val, predictions_proba_val)\n",
    "    \n",
    "    return best_f1 \n",
    "\n",
    "# study\n",
    "study = optuna.create_study(direction='maximize')  # Максимизация F1-score\n",
    "\n",
    "# Запуск оптимизации\n",
    "study.optimize(objective, n_trials=30)  # Проводим 30 испытаний\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Лучшие параметры:\")\n",
    "print(study.best_params)\n",
    "print(\"Лучший F1-score:\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
